{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e519bc",
   "metadata": {},
   "source": [
    "# Análise da Correlação de Métricas de Países com sua Emissão de Carbono\n",
    "\n",
    "## Alunos\n",
    "\n",
    "- Bruno de Marco Appolonio - 195036\n",
    "- João Vitor Vendemiato Fatoretto - 199944\n",
    "- Lucas Costa de Oliveira - 182410\n",
    "- Natan Beltrão da Cunha Pevidor Carvalho - 184972\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Neste projeto, desenvolvemos uma solução em machine learning para um dos problemas relacionados com os [Objetivos de Desenvolvimento Sustentável](https://brasil.un.org/pt-br/sdgs) da ONU. Optamos por criar uma solução relacionado predominantemente com o objetivo 13 (Ação contra a mudança global do clima), porém relacionada também com outros objetivos.\n",
    "\n",
    "Buscamos analisar a correlação entre diversas métricas e a emissão de carbono anual de um país. As métricas avaliadas incluem tanto fatores diretamente relacionados com a pegada de carbono de um país (como desmatamento) tanto como métricas mais gerais (como liberdade de imprensa), permitindo estabelecer relações diversas.\n",
    "\n",
    "Como metodologia, aplicamos uma regressão linear sobre os diversos parâmetros, permitindo avaliar a relevância de cada um para o cálculo e criando um modelo de predição considerando mudanças nas métricas avaliadas.\n",
    "\n",
    "## Métricas Utilizadas\n",
    "\n",
    "Obtivemos as métricas de diversas fontes. Por isso, nem todos os dados estão disponíveis para todos os países avaliados ou para o mesmo ano. Utilizamos o dados mais recentes disponíveis em cada uma das fontes.\n",
    "\n",
    "### Our World in Data ([fonte](https://ourworldindata.org/co2-emissions))\n",
    "\n",
    "- Emissão de CO<sub>2</sub> em milhões de toneladas (2015 para Cuba, Coreia do Norte e Palestina, 2016 par países restantes)\n",
    "- PIB em dólares ajustdo para inflação de 2011 (2015 para Cuba, Coreia do Norte e Palestina, 2016 par países restantes)\n",
    "- População (2015 para Cuba, Coreia do Norte e Palestina, 2016 par países restantes)\n",
    "\n",
    "### ONU ([fonte](http://hdr.undp.org/en/indicators))\n",
    "\n",
    "- **Índice de gini de distribuição de renda familiar (anos variados)**\n",
    "- IDH (2019)\n",
    "- Porcentagem da população residindo em áreas urbanas (2019)\n",
    "- Porcentagem da variação na área de floresta (diferença entre 1990 e 2016)\n",
    "- **Porcentagem da energia consumida proveniente de combustíveis fósseis (anos variados)**\n",
    "- Porcentagem do Rendimento Nacional Bruto derivado da extração de recursos naturais (anos variados)\n",
    "- Índice de desigualdade de gênero (2019)\n",
    "- Expectativa de vida no nascimento (2019)\n",
    "- **Porcentagem da população vivendo abaixo da linha da pobreza (anos variados)**\n",
    "- **Porcentagem do PIB investido em pesquisa e desenvolvimento (anos variados)**\n",
    "- **Proporção dos gastos públicos em educação e saúde sobre gastos militares (anos variados)**\n",
    "- Porcentagem de importações e exportações sobre o PIB (anos variados)\n",
    "- **Índice de desemprego (2019)**\n",
    "\n",
    "### Center for Systemic Peace ([fonte](https://www.systemicpeace.org/polityproject.html))\n",
    "\n",
    "- Polity Score, índice que avalia o nível de democracia de cada país - removemos países com valores especiais para evitar interferência na regressão (2018)\n",
    "\n",
    "### Repórteres sem Fronteira ([fonte](https://rsf.org/en/ranking))\n",
    "\n",
    "- Índice de liberdade de imprensa (2021)\n",
    "\n",
    "### IMF ([fonte](https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD))\n",
    "\n",
    "- Crescimento econômico (optamos pelos dados de 2019, já que 2020 representa um outlier)\n",
    "\n",
    "**Dados em negrito estão disponíveis para menos de 90% dos países selecionados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cf5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Países: 164\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "data = {}\n",
    "\n",
    "co2_file_path = \"owid-co2-data.json\"\n",
    "with open(co2_file_path, 'r', encoding='utf8') as json_file:\n",
    "    co2_data = json.load(json_file)\n",
    "    for key in co2_data.keys():\n",
    "        if 'iso_code' in co2_data[key] and key != 'World':\n",
    "            for i in range(len(co2_data[key]['data'])):\n",
    "                if 'co2' in co2_data[key]['data'][i] and 'gdp' in co2_data[key]['data'][i] \\\n",
    "                        and 'population' in co2_data[key]['data'][i]:\n",
    "                    data[co2_data[key]['iso_code']] = {\n",
    "                        'name': key,\n",
    "                        'co2_emissions': co2_data[key]['data'][i]['co2'],\n",
    "                        'gdp': co2_data[key]['data'][i]['gdp'],\n",
    "                        'population': co2_data[key]['data'][i]['population']               \n",
    "                    }\n",
    "\n",
    "X_fields = ['gdp', 'population']\n",
    "                   \n",
    "def get_iso3_from_country_name(country_name):\n",
    "    iso3 = [key for key, values in data.items() if values['name'] == country_name]\n",
    "    return iso3[0] if iso3 else None\n",
    "\n",
    "def add_csv_data(file, country_row, data_row, data_name):\n",
    "    X_fields.append(data_name)\n",
    "    with open(file, encoding='utf8') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        co2_names = [(data[key]['name'], key) for key in data]\n",
    "        for line in reader:\n",
    "            country_key = get_iso3_from_country_name(line[country_row])\n",
    "            if country_key:\n",
    "                data[country_key][data_name] = float(line[data_row])\n",
    "\n",
    "def check_missing_countries(file, country_row):\n",
    "    with open(file, encoding='utf8') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        co2_names = [data[key]['name'] for key in data]\n",
    "        file_names = [line[country_row] for line in reader]\n",
    "        return [name for name in co2_names if name not in file_names]\n",
    "\n",
    "add_csv_data('gini-index.csv', 1, -2, 'gini_index')\n",
    "add_csv_data('hdi.csv', 1, -2, 'hdi')\n",
    "add_csv_data('urban-population.csv', 1, -2, 'urban_population')\n",
    "add_csv_data('forest-area-change.csv', 1, -2, 'forest_area_change')\n",
    "add_csv_data('fossil-fuel-percentage.csv', 1, -2, 'fossil_fuel_percentage')\n",
    "add_csv_data('natural-resource-depletion.csv', 1, -2, 'natural_resource_depletion')\n",
    "add_csv_data('gender-inequality-index.csv', 1, -2, 'gender_inequality_index')\n",
    "add_csv_data('life-expectancy.csv', 1, -2, 'life_expectancy')\n",
    "add_csv_data('poverty-line.csv', 1, -2, 'poverty_line')\n",
    "add_csv_data('research-and-development.csv', 1, -2, 'research_and_development')\n",
    "add_csv_data('education-health-military-expenses.csv', 1, -2, 'education_health_military_expenses')\n",
    "add_csv_data('exports-imports.csv', 1, -2, 'exports_imports')\n",
    "add_csv_data('unemployment.csv', 1, -2, 'unemployment')\n",
    "add_csv_data('democracy.csv', 4, 10, 'democracy')\n",
    "add_csv_data('press-freedom.csv', 3, 7, 'press_freedom')\n",
    "add_csv_data('economic-growth.csv', 0, -8, 'economic_growth')\n",
    "\n",
    "print('Países:', len(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c07c04",
   "metadata": {},
   "source": [
    "## Pré-processamento dos Dados\n",
    "\n",
    "Antes de executar a regressão, precisamos realizar algumas alterações nos dados para garantir um melhor resultado.\n",
    "\n",
    "### Imputação de Dados Faltantes\n",
    "\n",
    "Devido ao uso de diversas fontes de dados diferentes, muitas métricas não estão disponíveis para todos os países. Porém, o método de regressão linear não é capaz de lidar com valores nulos. Por isso, utilizamos um método simples de imputação de dados, onde valores nulos passam a ter o valor da média aritmética dos valores restantes. Essa atribuição tenta atribuir o valor que tenha o menor impacto possível no treinamento.\n",
    "\n",
    "### Separação de Dados de Treinamento e Teste\n",
    "\n",
    "Para validar nosso modelo, reservamos 10% dos países para teste no final e 90% para o treinamento e validações necessárias durante seu desenvolvimento.\n",
    "\n",
    "\n",
    "### Normalização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9b6c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training countries: ['Equatorial Guinea', 'Canada', 'Mauritania', 'Iceland', 'Azerbaijan', 'Mali', 'Hong Kong', 'Peru', 'Belarus', 'Sri Lanka', 'Chad', 'Indonesia', 'Switzerland', 'Poland', 'Syria', 'Angola', 'Slovakia', 'Algeria', 'Bangladesh', 'Oman', 'Zambia', 'Pakistan', 'Georgia', 'United Arab Emirates', 'Paraguay', 'Portugal', 'Armenia', 'Hungary', 'Kuwait', 'Morocco', 'Ireland', 'Croatia', 'Vietnam', 'Cuba', 'Trinidad and Tobago', 'Rwanda', 'Sierra Leone', 'Serbia', 'Cape Verde', 'Kyrgyzstan', 'Saudi Arabia', 'Barbados', 'Palestine', 'Turkey', 'Burundi', 'Slovenia', 'Guinea-Bissau', 'Eswatini', 'Dominican Republic', 'Ukraine', 'Venezuela', 'United Kingdom', 'Uzbekistan', 'North Macedonia', 'Congo', 'Kenya', 'Germany', 'Romania', 'Denmark', 'Sao Tome and Principe', 'Namibia', 'Gambia', 'Greece', 'Guinea', 'Tanzania', 'Uganda', 'Botswana', 'Colombia', 'Netherlands', 'Myanmar', 'Argentina', 'Sweden', 'Libya', 'Sudan', 'China', 'Taiwan', 'Nigeria', 'Costa Rica', 'Mozambique', 'Cyprus', 'Dominica', 'Niger', 'Montenegro', 'Yemen', 'Lesotho', 'Kazakhstan', 'Russia', 'Honduras', 'Gabon', 'Laos', 'Democratic Republic of Congo', 'Uruguay', 'Italy', 'Ethiopia', 'Saint Lucia', 'Guatemala', 'Haiti', 'Senegal', 'Bulgaria', 'Japan', 'Lebanon', 'Ecuador', 'United States', 'Albania', 'Liberia', 'Iraq', 'Estonia', 'Australia', 'Cameroon', 'Panama', 'Iran', 'Chile', 'Mexico', 'Bahrain', 'Bolivia', 'Zimbabwe', 'Djibouti', 'Jordan', 'Madagascar', 'Luxembourg', 'Brazil', 'Finland', 'Afghanistan', 'Philippines', 'Benin', 'Tunisia', 'South Africa', 'Turkmenistan', 'New Zealand', 'Belgium', 'Comoros', 'Lithuania']\n",
      "Validation countries: ['Togo', 'North Korea', 'Cambodia', 'Tajikistan', 'Nepal', 'Malta', 'Jamaica', 'Bosnia and Herzegovina', 'Seychelles', 'India', 'Israel', 'Mongolia', 'Latvia', 'Norway', 'Burkina Faso']\n",
      "Testing countries: ['Thailand', 'Malawi', 'Nicaragua', 'Austria', 'Mauritius', 'Ghana', 'South Korea', 'El Salvador', 'Central African Republic', 'Egypt', 'Spain', 'Moldova', 'Singapore', 'France', 'Malaysia', 'Qatar', 'Czechia']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "countries = []\n",
    "X = []\n",
    "y = []\n",
    "for values in data.values():\n",
    "    countries.append(values['name'])\n",
    "    y.append(values['co2_emissions'])\n",
    "    X.append([values[field] if field in values else np.nan for field in X_fields])\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp.fit_transform(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test, countries_train_val, countries_test \\\n",
    "        = train_test_split(X, y, countries, test_size=0.1, random_state=0)\n",
    "X_train, X_val, y_train, y_val, countries_train, countries_val \\\n",
    "        = train_test_split(X_train_val, y_train_val, countries_train_val, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "def normalize(array):\n",
    "    min_by_feature = array.min(axis=0)\n",
    "    max_by_feature = array.max(axis=0)\n",
    "    \n",
    "    normalized_array = array.copy()\n",
    "    \n",
    "    for j in range(0, len(array[0])):\n",
    "        for i in range(0, len(array)):\n",
    "            normalized_array[i, j] = (array[i, j] - min_by_feature[j]) / (max_by_feature[j] - min_by_feature[j])\n",
    "    \n",
    "    return normalized_array\n",
    "\n",
    "# X_train = normalize(X_train)\n",
    "# X_test = normalize(X_test)\n",
    "\n",
    "# print(X_test)\n",
    "# print(y_test)\n",
    "\n",
    "print(\"Training countries:\", countries_train)\n",
    "print(\"Validation countries:\", countries_val)\n",
    "print(\"Testing countries:\", countries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27417c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9677301515789275\n",
      "Intercept\n",
      "151.72880623238964\n",
      "Coeficiente\n",
      "[ 2.57922588e-10  3.36547603e-06  5.96723369e-01 -2.20050603e+02\n",
      " -6.18931214e-01  7.57164826e-01  1.19635453e+00  2.22356302e+00\n",
      " -2.78928475e+02 -5.83644275e-01  3.06182388e-01 -8.78635125e+00\n",
      " -5.92708529e-01  6.30778339e-01  5.24369137e+00 -6.90130628e+00\n",
      " -2.16314707e+00 -2.53890741e+00]\n",
      "Erro pela media quadratica\n",
      "982049.9851819441\n",
      "Erro pela raiz da media quadratica\n",
      "990.9843516332355\n",
      "Erro pela media absoluta\n",
      "317.874887530219\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.098</td>\n",
       "      <td>-143.727895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.621</td>\n",
       "      <td>-62.852340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.724</td>\n",
       "      <td>-70.335722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.305</td>\n",
       "      <td>-48.760434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841</td>\n",
       "      <td>-129.812271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.399</td>\n",
       "      <td>-0.614451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.141</td>\n",
       "      <td>-63.141655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.733</td>\n",
       "      <td>51.005729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.594</td>\n",
       "      <td>-43.129873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2392.360</td>\n",
       "      <td>6219.246443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.907</td>\n",
       "      <td>-35.263280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.324</td>\n",
       "      <td>-25.822462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.221</td>\n",
       "      <td>-63.933338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.473</td>\n",
       "      <td>-0.637321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.381</td>\n",
       "      <td>-16.904099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual    Predicted\n",
       "0      3.098  -143.727895\n",
       "1     24.621   -62.852340\n",
       "2      9.724   -70.335722\n",
       "3      6.305   -48.760434\n",
       "4      8.841  -129.812271\n",
       "5      1.399    -0.614451\n",
       "6      8.141   -63.141655\n",
       "7     21.733    51.005729\n",
       "8      0.594   -43.129873\n",
       "9   2392.360  6219.246443\n",
       "10    63.907   -35.263280\n",
       "11    25.324   -25.822462\n",
       "12     7.221   -63.933338\n",
       "13    44.473    -0.637321\n",
       "14     3.381   -16.904099"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regressao linear normal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "#Utilizando a mesma regressão logistica com liblinear pois é o recomendado para datasets pequenos(<10000)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(\"Intercept\")\n",
    "print(reg.intercept_)\n",
    "print(\"Coeficiente\")\n",
    "print(reg.coef_)\n",
    "y_pred = reg.predict(X_val)\n",
    "errors = mean_squared_error(y_val, y_pred)\n",
    "print(\"Erro pela media quadratica\")\n",
    "print(errors)\n",
    "errors2 = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(\"Erro pela raiz da media quadratica\")\n",
    "print(errors2)\n",
    "errors3 = mean_absolute_error(y_val, y_pred)\n",
    "print(\"Erro pela media absoluta\")\n",
    "print(errors3)\n",
    "df = pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927961c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro pela media quadratica\n",
      "561702.8488759332\n",
      "Erro pela raiz da media quadratica\n",
      "749.4683775023021\n",
      "Erro pela media absoluta\n",
      "207.0719333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.098</td>\n",
       "      <td>3.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.621</td>\n",
       "      <td>7.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.724</td>\n",
       "      <td>7.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.305</td>\n",
       "      <td>6.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841</td>\n",
       "      <td>7.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.399</td>\n",
       "      <td>7.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.141</td>\n",
       "      <td>6.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.733</td>\n",
       "      <td>9.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2392.360</td>\n",
       "      <td>5292.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.907</td>\n",
       "      <td>84.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.324</td>\n",
       "      <td>7.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.221</td>\n",
       "      <td>13.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.473</td>\n",
       "      <td>166.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.381</td>\n",
       "      <td>3.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "0      3.098      3.004\n",
       "1     24.621      7.726\n",
       "2      9.724      7.726\n",
       "3      6.305      6.207\n",
       "4      8.841      7.154\n",
       "5      1.399      7.368\n",
       "6      8.141      6.987\n",
       "7     21.733      9.905\n",
       "8      0.594      0.539\n",
       "9   2392.360   5292.268\n",
       "10    63.907     84.154\n",
       "11    25.324      7.368\n",
       "12     7.221     13.328\n",
       "13    44.473    166.282\n",
       "14     3.381      3.107"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regressao linear com arvore de decisão\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "#Utilizando a mesma regressão logistica com liblinear pois é o recomendado para datasets pequenos(<10000)\n",
    "reg =  tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "errors = mean_squared_error(y_val, y_pred)\n",
    "print(\"Erro pela media quadratica\")\n",
    "print(errors)\n",
    "errors2 = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(\"Erro pela raiz da media quadratica\")\n",
    "print(errors2)\n",
    "errors3 = mean_absolute_error(y_val, y_pred)\n",
    "print(\"Erro pela media absoluta\")\n",
    "print(errors3)\n",
    "df = pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf95bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro pela media quadratica\n",
      "1.6908132647131286e+21\n",
      "Erro pela raiz da media quadratica\n",
      "41119499811.0766\n",
      "Erro pela media absoluta\n",
      "12088179142.964413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.098</td>\n",
       "      <td>2.474834e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.621</td>\n",
       "      <td>9.047323e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.724</td>\n",
       "      <td>1.107054e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.305</td>\n",
       "      <td>6.208321e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841</td>\n",
       "      <td>1.579402e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.399</td>\n",
       "      <td>2.546520e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.141</td>\n",
       "      <td>4.480072e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.733</td>\n",
       "      <td>8.797722e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.594</td>\n",
       "      <td>4.856338e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2392.360</td>\n",
       "      <td>1.589096e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.907</td>\n",
       "      <td>5.609009e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.324</td>\n",
       "      <td>7.072699e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.221</td>\n",
       "      <td>9.624646e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.473</td>\n",
       "      <td>8.402425e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.381</td>\n",
       "      <td>6.413862e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual     Predicted\n",
       "0      3.098  2.474834e+08\n",
       "1     24.621  9.047323e+08\n",
       "2      9.724  1.107054e+09\n",
       "3      6.305  6.208321e+08\n",
       "4      8.841  1.579402e+09\n",
       "5      1.399  2.546520e+08\n",
       "6      8.141  4.480072e+08\n",
       "7     21.733  8.797722e+08\n",
       "8      0.594  4.856338e+07\n",
       "9   2392.360  1.589096e+11\n",
       "10    63.907  5.609009e+09\n",
       "11    25.324  7.072699e+08\n",
       "12     7.221  9.624646e+08\n",
       "13    44.473  8.402425e+09\n",
       "14     3.381  6.413862e+08"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regressao linear com rede neural\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "#Utilizando a mesma regressão logistica com liblinear pois é o recomendado para datasets pequenos(<10000)\n",
    "reg =  MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "errors = mean_squared_error(y_val, y_pred)\n",
    "print(\"Erro pela media quadratica\")\n",
    "print(errors)\n",
    "errors2 = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(\"Erro pela raiz da media quadratica\")\n",
    "print(errors2)\n",
    "errors3 = mean_absolute_error(y_val, y_pred)\n",
    "print(\"Erro pela media absoluta\")\n",
    "print(errors3)\n",
    "df = pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe3a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro pela media quadratica\n",
      "129374.74372013337\n",
      "Erro pela raiz da media quadratica\n",
      "359.687007994636\n",
      "Erro pela media absoluta\n",
      "102.71026666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.098</td>\n",
       "      <td>2.3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.621</td>\n",
       "      <td>11.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.724</td>\n",
       "      <td>26.3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.305</td>\n",
       "      <td>5.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841</td>\n",
       "      <td>9.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.399</td>\n",
       "      <td>2.3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.141</td>\n",
       "      <td>2.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.733</td>\n",
       "      <td>9.4695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2392.360</td>\n",
       "      <td>1001.8385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.907</td>\n",
       "      <td>66.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.324</td>\n",
       "      <td>13.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.221</td>\n",
       "      <td>11.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.473</td>\n",
       "      <td>123.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.381</td>\n",
       "      <td>5.1730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "0      3.098     2.3890\n",
       "1     24.621    11.6705\n",
       "2      9.724    26.3720\n",
       "3      6.305     5.5555\n",
       "4      8.841     9.0665\n",
       "5      1.399     2.3890\n",
       "6      8.141     2.3745\n",
       "7     21.733     9.4695\n",
       "8      0.594     0.3130\n",
       "9   2392.360  1001.8385\n",
       "10    63.907    66.2000\n",
       "11    25.324    13.5090\n",
       "12     7.221    11.6705\n",
       "13    44.473   123.6725\n",
       "14     3.381     5.1730"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regressao linear com k vizinhos\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "#Utilizando a mesma regressão logistica com liblinear pois é o recomendado para datasets pequenos(<10000)\n",
    "reg =  KNeighborsRegressor(n_neighbors=2).fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "errors = mean_squared_error(y_val, y_pred)\n",
    "print(\"Erro pela media quadratica\")\n",
    "print(errors)\n",
    "errors2 = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(\"Erro pela raiz da media quadratica\")\n",
    "print(errors2)\n",
    "errors3 = mean_absolute_error(y_val, y_pred)\n",
    "print(\"Erro pela media absoluta\")\n",
    "print(errors3)\n",
    "df = pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6426cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
